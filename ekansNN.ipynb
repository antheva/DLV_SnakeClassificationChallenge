{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.utils.data \n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import os \n",
    "import glob\n",
    "from shutil import copyfile\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import random\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation of the sampler weights for each images based on the class\n",
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = float(nclasses)/(N*float(count[i]))                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories to split train and validation sets accordingly\n",
    "directories = [\"/home/Anthony/data/train_data\", \"/home/Anthony/data/val_data\"] \n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "for i in os.listdir(\"/home/Anthony/data/train\"):\n",
    "    if not os.path.exists(os.path.join(directories[0], i)):\n",
    "        os.makedirs(os.path.join(directories[0], i))\n",
    "    if not os.path.exists(os.path.join(directories[1], i)):\n",
    "        os.makedirs(os.path.join(directories[1], i))    \n",
    "        \n",
    "train_fraction = 0.8\n",
    "\n",
    "for i in os.listdir(\"/home/Anthony/data/train\"):\n",
    "    images = os.listdir(os.path.join(\"/home/Anthony/data/train/\", i))\n",
    "    n_images = len(images)\n",
    "    n_train_images = int(n_images*train_fraction)\n",
    "    n_val_images = n_images - n_train_images\n",
    "\n",
    "    for j in range(n_train_images):\n",
    "        copyfile(os.path.join(os.path.join(\"/home/Anthony/data/train/\", i), images[j]) , os.path.join(os.path.join(\"/home/Anthony/data/train_data/\", i), images[j]))\n",
    "        \n",
    "    for j in range(n_val_images):\n",
    "        copyfile(os.path.join(os.path.join(\"/home/Anthony/data/train/\", i), images[n_train_images + j]) , os.path.join(os.path.join(\"/home/Anthony/data/val_data/\", i), images[n_train_images + j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataset = ImageFolder(root='/home/Anthony/data/train')\n",
    "\n",
    "class_names = dataset.classes\n",
    "print(class_names)\n",
    "print('Dataset size = {:.0f}'.format(len(dataset)))\n",
    "\n",
    "TRAIN_TRANSF = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "VAL_TRANSF = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_set = ImageFolder(root='/home/Anthony/data/train_data', transform=TRAIN_TRANSF,)\n",
    "val_set = ImageFolder(root='/home/Anthony/data/val_data', transform=VAL_TRANSF,)\n",
    "\n",
    "# For unbalanced dataset we create a weighted sampler                       \n",
    "weights = make_weights_for_balanced_classes(train_set.imgs, len(dataset.classes))                                                                \n",
    "weights = torch.DoubleTensor(weights)                                       \n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "\n",
    "train_size = len(train_set)\n",
    "val_size = len(val_set)\n",
    "print('Train size = {:.0f}, Val size = {:.0f}'.format(train_size, val_size))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_set, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available.\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show one image of the training set\n",
    "i = 10\n",
    "img = (train_set[i][0])\n",
    "img = img.numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "plt.imshow(img)\n",
    "\n",
    "print(train_set[i][0].shape)\n",
    "print(class_names[train_set[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            i = 1\n",
    "            # Iterate over data.\n",
    "            if phase == 'train':\n",
    "                for inputs, labels in train_data_loader:\n",
    "                    if (i%100==0):\n",
    "                        print('Batch {:.0f}/{:.0f}\\r'.format(i, train_size/batch_size),)\n",
    "                    i += 1\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "                    \n",
    "                epoch_loss = running_loss / train_size\n",
    "                epoch_acc = running_corrects.double() / train_size\n",
    "            \n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                        phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val':\n",
    "                for inputs, labels in val_data_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / val_size\n",
    "                epoch_acc = running_corrects.double() / val_size\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                        phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model, 'snakes_2.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained model selection\n",
    "model = models.resnext50_32x4d(pretrained=True)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of blocks in the model\n",
    "count = 0\n",
    "for child in model.children():\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze half of he network\n",
    "\n",
    "#count = 0\n",
    "#for child in model.children():\n",
    "#    count+=1\n",
    "#    if count < 7:\n",
    "#        for param in child.parameters():\n",
    "#            param.requires_grad = False\n",
    "    \n",
    "\n",
    "num_classes = 45\n",
    "\n",
    "#add a more complex fc network at the end\n",
    "\n",
    "#num_ftrs = model.fc.in_features\n",
    "#print(num_ftrs)\n",
    "#model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "#model.classifier = nn.Sequential(nn.Linear(25088, 4096, bias=True),\n",
    " #                               nn.ReLU(),\n",
    "  #                              nn.Dropout(0.5),\n",
    "   #                             nn.Linear(4096, 256, bias=True),\n",
    "    #                            nn.ReLU(),\n",
    "     #                           nn.Dropout(0.5),\n",
    "      #                          nn.Linear(256, num_classes))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015, weight_decay=1e-5)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss = ['pantherophis_spiloides', 'crotalus_pyrrhus','nerodia_rhombifer','pantherophis_alleghaniensis','thamnophis_sirtalis', 'natrix_natrix','crotalus_adamanteus','charina_bottae','pituophis_catenifer',\n",
    "        'lampropeltis_triangulum','nerodia_erythrogaster','thamnophis_marcianus','thamnophis_proximus','lampropeltis_californiae','crotalus_ruber','rhinocheilus_lecontei','opheodrys_aestivus','thamnophis_ordinoides',\n",
    "        'thamnophis_radix','masticophis_flagellum','pantherophis_vulpinus','hierophis_viridiflavus','heterodon_platirhinos','pantherophis_emoryi','regina_septemvittata','haldea_striatula','diadophis_punctatus',\n",
    "        'nerodia_fasciata','storeria_occipitomaculata','crotalus_scutulatus','nerodia_sipedon','storeria_dekayi','crotalus_viridis','opheodrys_vernalis','boa_imperator','pantherophis_obsoletus','crotalus_horridus',\n",
    "        'lichanura_trivirgata','agkistrodon_contortrix','thamnophis_elegans','agkistrodon_piscivorus','pantherophis_guttatus','crotalus_atrox','carphophis_amoenus','coluber_constrictor']\n",
    "\n",
    "\n",
    "nb_classes = 45\n",
    "model.eval()\n",
    "\n",
    "#compute confusion matrix\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(val_data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_mat = confusion_matrix.numpy()\n",
    "conf_mat_norm = conf_mat / conf_mat.max(axis=1)\n",
    "df_cm = pd.DataFrame(conf_mat_norm, index = [i for i in clss],\n",
    "                  columns = [i for i in clss])\n",
    "plt.figure(figsize = (20,14))\n",
    "sn.heatmap(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of submission file\n",
    "\n",
    "AICROWD_TEST_IMAGES_PATH = os.getenv('AICROWD_TEST_IMAGES_PATH', '/home/Anthony/data/test/round1')\n",
    "AICROWD_PREDICTIONS_OUTPUT_PATH = os.getenv('AICROWD_PREDICTIONS_OUTPUT_PATH', '/home/Anthony/data/submission_resnext50.csv')\n",
    "\n",
    "test_data = ImageFolder(root='/home/Anthony/data/test', transform=VAL_TRANSF)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, 1, shuffle=False)\n",
    "model.eval()\n",
    "print('Total test images {:.0f}'.format(len(test_data)))\n",
    "\n",
    "LINES = []\n",
    "\n",
    "#with open('/home/Anthony/data/class_idx_mapping.csv') as f:\n",
    "#    classes = ['filename']\n",
    "#    for line in f.readlines()[1:]:\n",
    "#        class_name = line.split(\",\")[0]\n",
    "#        classes.append(class_name)\n",
    "\n",
    "LINES.append(','.join(clss))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "k=0    \n",
    "images_path = AICROWD_TEST_IMAGES_PATH + '/*.jpg'\n",
    "for inp, _ in test_data_loader:\n",
    "    inp = inp.to(device)    \n",
    "    _file_path = glob.glob(images_path)[k]\n",
    "    out = (model(inp).data[0].cpu().numpy())\n",
    "    probs = softmax(out)\n",
    "    probs = list(map(str, probs))\n",
    "    LINES.append(\",\".join([os.path.basename(_file_path)] + probs))\n",
    "    if (k % 1000 == 0):\n",
    "        print('Total predictions so far {:.0f}'.format(k))\n",
    "    k += 1\n",
    "    \n",
    "\n",
    "fp = open(AICROWD_PREDICTIONS_OUTPUT_PATH, \"w\")\n",
    "fp.write(\"\\n\".join(LINES))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASIC PIPELINE FOR ALL EXPERIMENTS\n",
    "\n",
    "-Split the dataset into training and validation data\n",
    "\n",
    "-Preprocess the images (normalize and crop), so they fit into the model we will be using\n",
    "\n",
    "-Upload a pretrained model and add a fully connected layer to it in order to fine tune the model on our data\n",
    "\n",
    "-Train our model for 5 epochs (or more) and check accuracy on the validation data\n",
    "\n",
    "\n",
    "• First approach\n",
    "\n",
    "The first approach was to set up all the code for dataset splitting, preprocessing, training and submission creation, and to build a very simple model (only two stacked convolutional layers with max pooling and dropout, with a final fully connected layer) to test if the code worked in the right way. \n",
    "As expected the simple model was not suitable for the given classification problem and obtained a max of 0.21 accuracy on the validation set.\n",
    "\n",
    "\n",
    "• Transfer learning\n",
    "\n",
    "As the simple CNN used at the beginnning did not provide satisfying results at all, one of the pretrained models available in the pytorch libraries was uploaded in order to perform transfer learning. \n",
    "\n",
    "-The first model chosen was ResNet-18. Only the second half of the network was trained, using the SGD optimizer for 5 epochs, without augmentation of the training data. The best validation accuracy was 0.53, that is a good improvement wrt the previous model.\n",
    "\n",
    "-A different optimizer was tested. The same previous network was trained with the Adam optimizer obtaining a 0.56 acc on val set.\n",
    "\n",
    "-A second fully connected layer was added in order to not pass directly from a 512dim feature vector to the 45 classes of the classifier, but that worsen the validation accuracy to 0.51, probably because the number of neurons was not chosen appropriately and the optimizer learning rate was not good enough. \n",
    "For the next models the second fc layer was not taken into consideration, also because its addition increases the training time.\n",
    "\n",
    "-The following solution was to use a deeper architecture. The new chosen model was ResNet-50. Also in this case only the second half of the layers was trained, with Adam optimizer and for 5 epochs, without augmentation of the training data. The deeper model obtained an accuracy of 0.62 on the validation set.\n",
    "\n",
    "-Without going even deeper (incresing significantly the training time), using for example ResNet-101 or ResNet-152, the new solution was to upload a more complex model: ResNext-50 (32x4d), which obtains better results on the Imagenet dataset wrt ResNet-50. \n",
    "In this step a data augmentation on the training set was performed (random rotations, horizontal and vertical flips). \n",
    "The model was trained in three different ways:\n",
    "-only final fully connected layer trained, with all pretrained parameters frozen => 0.46 accuracy on val set\n",
    "-second half of the network trained, with the other parameters frozen => 0.64 accuracy on val set\n",
    "-entire network trained, no parameters frozen => 0.68 accuracy on val set\n",
    "\n",
    "-The last solution was to add a sampler to the data loader, in order to take account for the classes imbalance. The sampler simply takes for the training process the images belonging to a low represented class with high probability, while the images belonging to a class containing a high number of elements are sampled with low probability. \n",
    "This solution worsened the results for the ResNext-50 with half parameters frozen obtaining a max accuracy of 0.59 (the network converged slowly so it was trained for 15 epochs). This was probably due to the presence of the same classes imbalance in the validation set.\n",
    "\n",
    "-The batch size used for all the experiments was 64. A couple of initial tests showed that a different size (for example 32 or 128) do not affect very much the results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
